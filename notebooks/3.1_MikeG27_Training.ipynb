{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Basic libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Computer Vision \n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import measure\n",
    "import datetime\n",
    "\n",
    "#Deep learning libraries  \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from keras import objectives\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, UpSampling2D, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import ELU\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Custom\n",
    "import config\n",
    "from src.models.callbacks import tensorboard,checkpoint,reduce_lr\n",
    "from src.visualization.visualize import plot_learning_curve\n",
    "from config import intermediate_dim,latent_dim,batch_size,epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(config.DATA_PREPROCESSED_DIR,\"X_train.npy\"))\n",
    "X_valid = np.load(os.path.join(config.DATA_PREPROCESSED_DIR,\"X_valid.npy\"))\n",
    "\n",
    "y_train = np.load(os.path.join(config.DATA_PREPROCESSED_DIR,\"y_train.npy\"))\n",
    "y_valid = np.load(os.path.join(config.DATA_PREPROCESSED_DIR,\"y_valid.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vae(input_shape):\n",
    "\n",
    "    #input_shape=(30,30,1)\n",
    "    \n",
    "    width = input_shape[0]\n",
    "    height = input_shape[1]\n",
    "    channels = input_shape[2] \n",
    "    \n",
    "    #encoder\n",
    "    input_img = Input(batch_shape=(None,30,30,1))\n",
    "    squeeze=Conv2D(256, 3,3,padding='same',input_shape=input_shape)(input_img)\n",
    "    squeeze=Activation('relu')(squeeze)\n",
    "    squeeze=BatchNormalization()(squeeze)\n",
    "    squeeze=MaxPooling2D(pool_size=(2,2))(squeeze)\n",
    "    squeeze=UpSampling2D(size=(2, 2))(squeeze)\n",
    "\n",
    "    #bottleneck\n",
    "    squeeze=Conv2D(128, 3,3, kernel_initializer='glorot_uniform')(squeeze)\n",
    "\n",
    "    squeeze0=Activation('relu')(squeeze)\n",
    "    squeeze0=Dense(100)(squeeze0)\n",
    "    squeeze0=Reshape((30,30))(squeeze0)\n",
    "    squeeze0=Activation('relu')(squeeze0)\n",
    "\n",
    "    model = Model(inputs = input_img, outputs = squeeze0)\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/michal/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30, 30, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 10, 10, 256)       2560      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 128)         295040    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3, 3, 100)         12900     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 30, 30)            0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30)            0         \n",
      "=================================================================\n",
      "Total params: 311,524\n",
      "Trainable params: 311,012\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(30,30,1)\n",
    "vae = build_vae(input_shape)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_samples = X_train.shape[0]\n",
    "n_valid_samples = X_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(n_train_samples,input_shape[1],input_shape[1],1)\n",
    "y_train = y_train.reshape(n_train_samples,input_shape[1],input_shape[1])\n",
    "X_valid = X_valid.reshape(n_valid_samples,input_shape[1],input_shape[1],1)\n",
    "y_valid = y_valid.reshape(n_valid_samples,input_shape[1],input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes before training\n",
      "\n",
      "X_train :  (900, 30, 30, 1)\n",
      "y_train :  (900, 30, 30)\n",
      "X_valid :  (120, 30, 30, 1)\n",
      "y_valid :  (120, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes before training\\n\")\n",
    "print(\"X_train : \",X_train.shape)\n",
    "print(\"y_train : \",y_train.shape)\n",
    "print(\"X_valid : \",X_valid.shape)\n",
    "print(\"y_valid : \",y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.RMSprop(lr=0.0005, rho=0.9, epsilon=None, decay=0.0)\n",
    "loss = 'mean_squared_error'\n",
    "vae.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 120 samples\n",
      "Epoch 1/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0900\n",
      "Epoch 00001: val_loss improved from inf to 0.09126, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 2s 2ms/sample - loss: 0.0899 - val_loss: 0.0913\n",
      "Epoch 2/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0845\n",
      "Epoch 00002: val_loss improved from 0.09126 to 0.08698, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0845 - val_loss: 0.0870\n",
      "Epoch 3/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0821\n",
      "Epoch 00003: val_loss did not improve from 0.08698\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0821 - val_loss: 0.0883\n",
      "Epoch 4/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0802\n",
      "Epoch 00004: val_loss improved from 0.08698 to 0.08355, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0802 - val_loss: 0.0835\n",
      "Epoch 5/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0792\n",
      "Epoch 00005: val_loss improved from 0.08355 to 0.08330, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0792 - val_loss: 0.0833\n",
      "Epoch 6/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0773\n",
      "Epoch 00006: val_loss improved from 0.08330 to 0.08072, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0774 - val_loss: 0.0807\n",
      "Epoch 7/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0768\n",
      "Epoch 00007: val_loss did not improve from 0.08072\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0769 - val_loss: 0.0811\n",
      "Epoch 8/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0760\n",
      "Epoch 00008: val_loss did not improve from 0.08072\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0760 - val_loss: 0.0811\n",
      "Epoch 9/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0746\n",
      "Epoch 00009: val_loss improved from 0.08072 to 0.07894, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0747 - val_loss: 0.0789\n",
      "Epoch 10/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0740\n",
      "Epoch 00010: val_loss did not improve from 0.07894\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0741 - val_loss: 0.0790\n",
      "Epoch 11/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0734\n",
      "Epoch 00011: val_loss did not improve from 0.07894\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0734 - val_loss: 0.0793\n",
      "Epoch 12/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0724\n",
      "Epoch 00012: val_loss improved from 0.07894 to 0.07837, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0725 - val_loss: 0.0784\n",
      "Epoch 13/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0722\n",
      "Epoch 00013: val_loss did not improve from 0.07837\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0721 - val_loss: 0.0802\n",
      "Epoch 14/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0714\n",
      "Epoch 00014: val_loss did not improve from 0.07837\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0714 - val_loss: 0.0789\n",
      "Epoch 15/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0707\n",
      "Epoch 00015: val_loss did not improve from 0.07837\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0706 - val_loss: 0.0794\n",
      "Epoch 16/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0706\n",
      "Epoch 00016: val_loss did not improve from 0.07837\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0705 - val_loss: 0.0791\n",
      "Epoch 17/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0704\n",
      "Epoch 00017: val_loss did not improve from 0.07837\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0703 - val_loss: 0.0796\n",
      "Epoch 18/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0707\n",
      "Epoch 00018: val_loss improved from 0.07837 to 0.07766, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0707 - val_loss: 0.0777\n",
      "Epoch 19/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0694\n",
      "Epoch 00019: val_loss did not improve from 0.07766\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0694 - val_loss: 0.0783\n",
      "Epoch 20/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0693\n",
      "Epoch 00020: val_loss did not improve from 0.07766\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0693 - val_loss: 0.0787\n",
      "Epoch 21/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0686\n",
      "Epoch 00021: val_loss improved from 0.07766 to 0.07750, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0686 - val_loss: 0.0775\n",
      "Epoch 22/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0688\n",
      "Epoch 00022: val_loss did not improve from 0.07750\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0689 - val_loss: 0.0776\n",
      "Epoch 23/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0686\n",
      "Epoch 00023: val_loss improved from 0.07750 to 0.07719, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0686 - val_loss: 0.0772\n",
      "Epoch 24/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0677\n",
      "Epoch 00024: val_loss did not improve from 0.07719\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0677 - val_loss: 0.0774\n",
      "Epoch 25/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0671\n",
      "Epoch 00025: val_loss did not improve from 0.07719\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0672 - val_loss: 0.0783\n",
      "Epoch 26/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0685\n",
      "Epoch 00026: val_loss did not improve from 0.07719\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0684 - val_loss: 0.0788\n",
      "Epoch 27/500\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.0685\n",
      "Epoch 00027: val_loss improved from 0.07719 to 0.07666, saving model to /home/michal/Desktop/ML_Projects/eeg2image/models/VAE.hdf5\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 0.0685 - val_loss: 0.0767\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fb6a7553c336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = vae.fit(X_train, y_train,verbose=1,\n\u001b[1;32m      2\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         batch_size=128,callbacks=[tensorboard,checkpoint,reduce_lr])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = vae.fit(X_train, y_train,verbose=1,\n",
    "        epochs=500,validation_data=(X_valid,y_valid),\n",
    "        batch_size=128,callbacks=[tensorboard,checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(history, figsize=(15, 5)):\n",
    "    fig,ax = plt.subplots(1,1,figsize=figsize)\n",
    "    # Plot training & validation loss values\n",
    "    ax.plot(history.history['loss'])\n",
    "    if \"val_loss\" in history.history:\n",
    "            ax.plot(history.history['val_loss'])\n",
    "            plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    ax.set_title('Model loss')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    plt.grid()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14, 6))\n",
    "#plt.suptitle(\"Results\",size = 20)\n",
    "\n",
    "columns = 6\n",
    "rows = 2\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    if i  <= columns:    \n",
    "   \n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        img = y_train[i].reshape(30,30)\n",
    "        plt.imshow(img,cmap=plt.cm.binary)\n",
    "        plt.title(\"Stimulus\")\n",
    "        \n",
    "    else : \n",
    "        \n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        x = X_train[i-columns].reshape(1,30,30,1)\n",
    "        x_test_encoded = model.predict(x, batch_size=1).reshape(30,30)\n",
    "        plt.imshow(x_test_encoded,cmap=plt.cm.binary)\n",
    "        \n",
    "        plt.title(\"From Brain \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(config.MODEL_DIR,\"VAE.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/michal/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/michal/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/michal/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(os.path.join(config.DATA_PREPROCESSED_DIR,\"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(config.DATA_PREPROCESSED_DIR,\"y_test.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_samples = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(n_test_samples,input_shape[1],input_shape[1],1)\n",
    "y_test = y_test.reshape(n_test_samples,input_shape[1],input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 267us/sample - loss: 0.0666\n"
     ]
    }
   ],
   "source": [
    "x = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06656740870740678"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(base_conda",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
